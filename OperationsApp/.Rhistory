pbs_cvp_new = pbs_sdp / pbs_p
pbs_tq_new =  (pbs_p/pbs_new_m) * (pbs_u_new^(sqrt(2*(pbs_new_m+1))-1)/(1-pbs_u_new)) * ((cva_new^2+pbs_cvp_new^2)/2)
#############################################################################
# Hospital Trauma Bays
htb_m = 6
htb_a = 30       # minutes
htb_cva = 1
htb_p = 90       # minutes
htb_sdp = 90     # minutes
htb_time = 24    # hours
htb_new_p = 60   # minutes
htb_new_cvp = 1.25
# HTB1 percent patients redirected
# HTB2 patients treated per day
# HTB3 loss change with p = 60 and cvp = 1.25*60
# HTB4 minimum m for loss of 10% without HTB3
# Loss r = p / a
htb_r = htb_p / htb_a
htb_loss = 0.05
htb_treated = ((60/(htb_a))*htb_time)*(1-htb_loss)
htb_new_r = htb_new_p / htb_a
htb_new_loss = 0.0121
htb_mimum_bays = 6
#############################################################################
# To do list
tdl_activity= c("snow shoes","nap","homework","facebook","Mother","food","friend")
tdl_time= c(120,100,80,60,30,20,10)
tdl_actTable = rbind(tdl_activity,tdl_time)[,order(tdl_time)]
TDL1 = tdl_actTable[1,5]
#############################################################################
#YourNurse
#############################################################################
# Answers
TO1 = to_totalreading ; TO1
TO2 = to_tq ; TO2
TO3 = to_total_charges ; TO3
PBS1 = lhs_tq ; PBS1
PBS2 = shc_tq ; PBS2
PBS3 = pbstimeoffwork ; PBS3
PBS4 = pbs_new_a ; PBS4
PBS5 = pbs_tq_new ; PBS5
HTB1 = htb_loss ; HTB1
HTB2 = htb_treated ; HTB2
HTB3 = "More patients will have immediate access..."; HTB3
HTB4 = htb_mimum_bays ; HTB4
TDL1
YN1 = "C"
qnorm(50,mean=47,sd=2)
qnorm(50, mean=47, sd=2, lower.tail=FALSE)
qnorm(p=50, mean=47, sd=2, lower.tail=FALSE)
pnorm(50, mean=47, sd=2, lower.tail=FALSE)
pnorm(44, 47, 2, lower.tail=TRUE)
# Homework 5
#####################################################
# 20-Station Assembly Line
sal_m = 20
sal_station_error = 0.005
sal_inspection_error = .20
sal_rework_error = .05
# 20SAL1 Likelihood of rework
20SAL1 = sal_m * sal_station_error * sal_inspection_error
# 20SAL2 Likelihood defect is shipped
20SAL2 = 20SAL1 * sal_rework_error
#####################################################
# 3-step process with rework
spr1_p = 7
spr2_p = 6
spr3_p = 5 # 1.4D
spr3_rework = .4
# 3SPR1 for every D how many units for 2nd step?
3SPR1 = 1.4
# 3SPR2 Step of bottleneck?
spr1_cap = 1/spr1_p
spr2_cap = 1/spr2_p
spr3_cap = 1/spr3_p
spr1_Util = 3SPR1/spr1_cap
spr2_Util = 3SPR1/spr2_cap
spr3_Util = 3SPR1/spr3_cap
3SPR2 = which.max(spr1_Util,spr2_Util,spr3_Util)
#####################################################
# Flu shot dosage
fd_recco = 0.5 # mL
fd_lsl = 0.45
fd_usl = 0.55
fd_m = 100
fd_avg = 0.5
fd_sd = 0.02
fd_goal_Cp = 4/3
# Cp = (usl-lsl) / 6 sd
# FD1 Capability score
FD1 = (fd_usl-fd_lsl)/(6*fd_sd)
# FD2 Percentage outside specs
# pnorm(usl, mean, sd, lower.tail=FALSE)
# pnorm(lsl, mean, sd, lower.tail=TRUE)
FD2 = pnorm(fd_usl, fd_avg, fd_sd, lower.tail=FALSE) + pnorm(fd_lsl, fd_avg, fd_sd, lower.tail=TRUE)
# FD3 max SD for Cp = 3/4
fd_sd_NEW = (fd_usl-fd_lsl) / (fd_goal_Cp*6)
20SAL1
20SAL2
3SPR1
3SPR2
FD1
FD2
FD3 = fd_sd_NEW ; FD3
KC1 = "c" ; KC1
sal_m = 20
sal_station_error = 0.005
sal_inspection_error = .20
sal_rework_error = .05
20SAL1 = sal_m * sal_station_error * sal_inspection_error
SAL1 = sal_m * sal_station_error * sal_inspection_error
# Homework 5
#####################################################
# 20-Station Assembly Line
sal_m = 20
sal_station_error = 0.005
sal_inspection_error = .20
sal_rework_error = .05
# 20SAL1 Likelihood of rework
SAL1 = sal_m * sal_station_error * sal_inspection_error
# 20SAL2 Likelihood defect is shipped
SAL2 = 20SAL1 * sal_rework_error
#####################################################
# 3-step process with rework
spr1_p = 7
spr2_p = 6
spr3_p = 5 # 1.4D
spr3_rework = .4
# 3SPR1 for every D how many units for 2nd step?
SPR1 = 1.4
# 3SPR2 Step of bottleneck?
spr1_cap = 1/spr1_p
spr2_cap = 1/spr2_p
spr3_cap = 1/spr3_p
spr1_Util = 3SPR1/spr1_cap
spr2_Util = 3SPR1/spr2_cap
spr3_Util = 3SPR1/spr3_cap
SPR2 = which.max(spr1_Util,spr2_Util,spr3_Util)
#####################################################
# Flu shot dosage
fd_recco = 0.5 # mL
fd_lsl = 0.45
fd_usl = 0.55
fd_m = 100
fd_avg = 0.5
fd_sd = 0.02
fd_goal_Cp = 4/3
# Cp = (usl-lsl) / 6 sd
# FD1 Capability score
FD1 = (fd_usl-fd_lsl)/(6*fd_sd)
# FD2 Percentage outside specs
# pnorm(usl, mean, sd, lower.tail=FALSE)
# pnorm(lsl, mean, sd, lower.tail=TRUE)
FD2 = pnorm(fd_usl, fd_avg, fd_sd, lower.tail=FALSE) + pnorm(fd_lsl, fd_avg, fd_sd, lower.tail=TRUE)
# FD3 max SD for Cp = 3/4
fd_sd_NEW = (fd_usl-fd_lsl) / (fd_goal_Cp*6)
SAL1
SAL2
SPR1
SPR2
FD1
FD2
FD3 = fd_sd_NEW ; FD3
KC1 = "c" ; KC1
# Homework 5
#####################################################
# 20-Station Assembly Line
sal_m = 20
sal_station_error = 0.005
sal_inspection_error = .20
sal_rework_error = .05
# 20SAL1 Likelihood of rework
SAL1 = sal_m * sal_station_error * sal_inspection_error
# 20SAL2 Likelihood defect is shipped
SAL2 = SAL1 * sal_rework_error
#####################################################
# 3-step process with rework
spr1_p = 7
spr2_p = 6
spr3_p = 5 # 1.4D
spr3_rework = .4
# 3SPR1 for every D how many units for 2nd step?
SPR1 = 1.4
# 3SPR2 Step of bottleneck?
spr1_cap = 1/spr1_p
spr2_cap = 1/spr2_p
spr3_cap = 1/spr3_p
spr1_Util = SPR1/spr1_cap
spr2_Util = SPR1/spr2_cap
spr3_Util = SPR1/spr3_cap
SPR2 = which.max(spr1_Util,spr2_Util,spr3_Util)
#####################################################
# Flu shot dosage
fd_recco = 0.5 # mL
fd_lsl = 0.45
fd_usl = 0.55
fd_m = 100
fd_avg = 0.5
fd_sd = 0.02
fd_goal_Cp = 4/3
# Cp = (usl-lsl) / 6 sd
# FD1 Capability score
FD1 = (fd_usl-fd_lsl)/(6*fd_sd)
# FD2 Percentage outside specs
# pnorm(usl, mean, sd, lower.tail=FALSE)
# pnorm(lsl, mean, sd, lower.tail=TRUE)
FD2 = pnorm(fd_usl, fd_avg, fd_sd, lower.tail=FALSE) + pnorm(fd_lsl, fd_avg, fd_sd, lower.tail=TRUE)
# FD3 max SD for Cp = 3/4
fd_sd_NEW = (fd_usl-fd_lsl) / (fd_goal_Cp*6)
SAL1
SAL2
SPR1
SPR2
FD1
FD2
FD3 = fd_sd_NEW ; FD3
KC1 = "c" ; KC1
SPR2 = max(spr1_Util,spr2_Util,spr3_Util)
SPR2 = which.max(spr1_Util,spr2_Util,spr3_Util)
# Homework 5
#####################################################
# 20-Station Assembly Line
sal_m = 20
sal_station_error = 0.005
sal_inspection_error = .20
sal_rework_error = .05
# 20SAL1 Likelihood of rework
SAL1 = sal_m * sal_station_error * sal_inspection_error
# 20SAL2 Likelihood defect is shipped
SAL2 = SAL1 * sal_rework_error
#####################################################
# 3-step process with rework
spr1_p = 7
spr2_p = 6
spr3_p = 5 # 1.4D
spr3_rework = .4
# 3SPR1 for every D how many units for 2nd step?
SPR1 = 1.4
# 3SPR2 Step of bottleneck?
spr1_cap = 1/spr1_p
spr2_cap = 1/spr2_p
spr3_cap = 1/spr3_p
spr1_Util = SPR1/spr1_cap
spr2_Util = SPR1/spr2_cap
spr3_Util = SPR1/spr3_cap
SPR2 = max(spr1_Util,spr2_Util,spr3_Util)
#####################################################
# Flu shot dosage
fd_recco = 0.5 # mL
fd_lsl = 0.45
fd_usl = 0.55
fd_m = 100
fd_avg = 0.5
fd_sd = 0.02
fd_goal_Cp = 4/3
# Cp = (usl-lsl) / 6 sd
# FD1 Capability score
FD1 = (fd_usl-fd_lsl)/(6*fd_sd)
# FD2 Percentage outside specs
# pnorm(usl, mean, sd, lower.tail=FALSE)
# pnorm(lsl, mean, sd, lower.tail=TRUE)
FD2 = pnorm(fd_usl, fd_avg, fd_sd, lower.tail=FALSE) + pnorm(fd_lsl, fd_avg, fd_sd, lower.tail=TRUE)
# FD3 max SD for Cp = 3/4
fd_sd_NEW = (fd_usl-fd_lsl) / (fd_goal_Cp*6)
SAL1
SAL2
SPR1
SPR2
FD1
FD2
FD3 = fd_sd_NEW ; FD3
KC1 = "c" ; KC1
SAL1 = * sal_station_error * sal_inspection_error
SAL1 = sal_station_error * sal_inspection_error
SAL2 = SAL1 * sal_rework_error
sal2
SAL2
# Final Exam 5
# 50 step assembly line
sal150_steps = 50
sal150_err = 0.01
sal150_ops = 2
sal150_qa_err = .1
# 50SAL1 prob defective
# 50SAL2 prob defective goes to shipping
SAL1150 = sal150_err*sal150_steps
SAL2150 = SAL1150+ (sal150_qa_err^sal150_ops)
#####################################
# Process with Scrap
ps1_1_p = 5
ps1_1_m = 1
ps1_2_p = 4
ps1_2_m = 2
ps1_2_scrap = .8
ps1_3_p = 20
ps1_3_m = 2
ps1_4_p = 12
ps1_4_m= 1
# PS1 how many units flow through 2nd step per 1 demand
PS1 = 1.8
# PS2 bottleneck
ps1_1_u = 1.8/(ps1_1_m/ps1_1_p)
ps1_2_u = 1.8/(ps1_2_m/ps1_2_p)
ps1_3_u = 1/(ps1_3_m/ps1_3_p)
ps1_4_u = 1/(ps1_4_m/ps1_4_p)
PS2 = max(ps1_1_u,ps1_2_u,ps1_3_u,ps1_4_u)
#####################################
# Lean Burgers
lb_usl = 95.5
lb_lsl = 94.5
lb_m = 30
lb_mean = 95
lb_sd = 0.25
lb_new_Cp = 1
# LB1 Cp score
# Cp = (usl-lsl) / 6 sd
LB_Cp = (lb_usl - lb_lsl) / (6*0.25)
# LB2 perc outside specs
LB2 = pnorm(lb_usl, lb_mean, lb_sd, lower.tail=FALSE) + pnorm(lb_lsl, lb_mean, lb_sd, lower.tail=TRUE)
# LB3 min SD for Cp = 1
lb_sd_NEW = (lb_usl-lb_lsl) / (lb_new_Cp*6)
SAL1150
SAL2150
PS1
PS2
LB1 = LB_Cp ; LB1
LB2
LB3 = lb_sd_NEW ; LB3
TJ1 = "g" ; TJ1
sal150_qa_err^sal150_ops
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$case, p=0.7, list=FALSE)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~., method="rpart", data=training)
install.packages("e1071")
modFit <- train(Case ~., method="rpart", data=training)
print(modFit$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart")
library(rpart)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# 1. Subset the data to a training set and testing set based on the Case
# variable in the data set.
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
# 2. Set the seed to 125 and fit a CART model with the rpart method
# using all predictor variables and default caret settings.
set.seed(125)
modFit <- train(Case ~., method="rpart", data=training)
# 3. In the final model what would be the final model prediction for
# cases with the following variable values:
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library("rpart.plot")
View(training)
inTrain <- createDataPartition(y=segmentationOriginal$Case == "Train", list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
# 2. Set the seed to 125 and fit a CART model with the rpart method
# using all predictor variables and default caret settings.
set.seed(125)
modFit <- train(Case ~., method="rpart", data=training)
# 3. In the final model what would be the final model prediction for
# cases with the following variable values:
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
modFit <- train(Class ~., method="rpart", data=training)
# 3. In the final model what would be the final model prediction for
# cases with the following variable values:
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
View(training)
training <- subset(segmentationOriginal, Case == "Train")
testing <- subset(segmentationOriginal, Case == "Test")
View(training)
set.seed(125)
modFit <- train(Class ~., method="rpart", data=training)
# 3. In the final model what would be the final model prediction for
# cases with the following variable values:
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("fancyRpartPlot")
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
fancyRpartPlot(modFit$finalModel)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
print(modFit$finalModel)
fancyRpartPlot(modFit)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
inTrainOlive <- createDataPartition(y=olive$Area, p=0.7, list=FALSE)
trainingOlive <- olive[inTrainOlive,]
testingOlive <- olive[-inTrainOlive,]
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
model <- train(Area ~ ., data = olive, method = "rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# Then set the seed to 13234 and fit a logistic regression
set.seed(13234)
library(caret)
modFitSA <- train(chd, age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
modFitSA <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(trainSA$chd, predict(modFitSA, trainSA))
missClass(testSA$chd, predict(model, testSA))
missClass(testSA$chd, predict(modFitSA, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
# Then set the seed to 33833.
set.seed(33833)
# Fit a random forest predictor relating the factor
# variable y to the remaining variables. Read about variable importance in random
# forests here: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
varImp(vowel.rfmodel)
setwd("/home/danilo/Coursera/Developing_Data_Products/OperationsApp/")
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
lines <<- c("a","b","c","d","e","f")
pr <<- c(44,40,55,60,50,40)  ## seconds
wage <- 25
# wage <- input$n
pr_T = 1/pr
bottleneck = min(pr_T)
bottleneckS = max(pr)
cap_hr = bottleneck*(60*60)
station_bottleneck <- which.min(pr_T)
cycle_time <- 1/bottleneckS
idle_time <- bottleneckS-pr
labor_util <- (sum(pr)) / ((sum(pr)+sum(idle_time)))
Utilization = bottleneck/pr_T
length(lines)*wage
direct_labor_cost_perRazor = (length(lines)*wage) / ((60*60)*bottleneck)
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
